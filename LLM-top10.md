### Prompt Injection

A Prompt Injection Vulnerability occurs when user prompts alter the LLMâ€™s behavior or output in
unintended ways. These inputs can affect the model even if they are imperceptible to humans,
therefore prompt injections do not need to be human-visible/readable, as long as the content is
parsed by the model.

- Direc Prompt Injection
- Indirec Prompt Injection



### Sensitive Information Disclosure
- PII
- Proprietary Algorithm Exposure
- Sensitive Business


### Supply Chain
- 
- Licensing Risks
- Outdated or Deprecated Models
- Vulnerable Pre-Trained Models


### Data and Model Poisoning


### Improper Output Handling

### Excessive Agency

### System Prompt Leakage

### Vector and Embedding Weaknesses

### Miss Information

### Unbounded Consumtion
